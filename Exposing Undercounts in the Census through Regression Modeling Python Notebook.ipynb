{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPPO1MhT8ZZrKXM79IGDQsa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Xax9paYfJcs6"},"outputs":[],"source":["#Importing Packages\n","\n","import os\n","import pandas as pd\n","from pandas.api.types import is_numeric_dtype\n","import string\n","import math\n","import numpy as np\n","import sklearn.linear_model\n","from sklearn.preprocessing import PolynomialFeatures\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","import warnings\n","warnings.filterwarnings(\"ignore\")x"]},{"cell_type":"code","source":["#Retrieving all the datasets necessary\n","\n","!wget https://ocrdata.ed.gov/assets/ocr/docs/2017-18-crdc-data.zip\n","!unzip 2017-18-crdc-data.zip\n","!wget https://ocrdata.ed.gov/assets/ocr/docs/2015-16-crdc-data.zip\n","!unzip 2015-16-crdc-data.zip\n","!wget https://ocrdata.ed.gov/assets/ocr/docs/2013-14-crdc-data.zip\n","!unzip 2013-14-crdc-data.zip\n","!wget https://ocrdata.ed.gov/assets/ocr/docs/2011-12-crdc-data.zip\n","!unzip 2011-12-crdc-data.zip\n","\n","!wget https://www.lep.gov/sites/lep/files/media/document/2020-03/acs2013_lep_allstate.csv\n","!wget https://www.lep.gov/sites/lep/files/media/document/2020-03/acs2014_lep_allstate.csv\n","!wget https://www.lep.gov/sites/lep/files/media/document/2020-03/acs2012_lep_allstate.csv\n","!wget https://data.humdata.org/dataset/e9988552-74e4-4ff4-943f-c782ac8bca87/resource/868a2fdb-f5c8-4a98-af7c-cfc8bf0daeb3/download/us-counties-countries-fb-social-connectedness-index-october-2021.tsv\n"],"metadata":{"id":"VOmL3-vAKHR5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Preproccessing 2015 CRDC Data\n","\n","enrollment2015 = pd.read_csv(\"Data Files and Layouts/CRDC 2015-16 School Data.csv\", encoding='windows-1252')\n","\n","column_renamer = {}\n","structure = pd.read_csv('Data Files and Layouts/CRDC 2015-16 School Data Record Layout.csv', encoding='windows-1252')\n","for index in structure.index:\n","  column_renamer[structure.loc[index, 'Field_Name']] = structure.loc[index, 'Field_Description']\n","enrollment2015.rename(column_renamer, axis=1, inplace = True)\n","\n","states = enrollment2015['District State Name'].unique()\n","state_totals2015 = pd.DataFrame()\n","for state in states:\n","  val = enrollment2015.loc[enrollment2015['District State Name'] == state]\n","  val = val.append(val.sum(numeric_only=True), ignore_index = True)\n","  row = val.iloc[-1:]\n","  row.rename(columns={\"District State Name\": \"State\"}, inplace = True)\n","  row.rename(index={(row.index[0]): int(np.where(states==state)[0][0])}, inplace = True)\n","  row[\"State\"][row.index[0]] = val['District State Abbreviation'][0]\n","  row.dropna(axis=1, inplace = True)\n","  state_totals2015 = state_totals2015.append(row)"],"metadata":{"id":"nooqMqFMLC1i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Visualizing the 2015 CRDC data - the graph below shows the number of LEP students in each state, classified by ethnicity\n","#(Hispanic students were shown in a seperate graph due to the higher magnitude of the population counts)\n","\n","from matplotlib.pyplot import figure\n","labels = state_totals2015['State']\n","plt.rcParams[\"figure.figsize\"] = [12.00, 5]\n","alpha = 0.5\n","fig, ax = plt.subplots()\n","\n","ax.bar(labels, state_totals2015['LEP Native American Students'].to_numpy(), width, label='LEP Native American Students', alpha = alpha)\n","ax.bar(labels, state_totals2015['LEP Asian Students'].to_numpy(), width, label='LEP Asian Students', alpha = alpha)\n","ax.bar(labels, state_totals2015['LEP Native Hawaiian Students'].to_numpy(), width, label='LEP Native Hawaiian Students', alpha = alpha)\n","ax.bar(labels, state_totals2015['LEP Black Students'].to_numpy(), width, label='LEP Black Students', alpha = alpha)\n","ax.bar(labels, state_totals2015['LEP White Students'].to_numpy(), width, label='LEP White Students' , alpha = alpha)\n","\n","ax.set_ylabel('Number of Students')\n","ax.set_title('CRDC Counts of LEP Students by State (2015)')\n","ax.legend()\n","\n","plt.xticks(rotation = 90)\n","plt.show()\n","\n","alpha = 1\n","fig, ax = plt.subplots()\n","ax.bar(labels, state_totals2015['LEP Hispanic Students'].to_numpy(), width, label='LEP Hispanic Students', alpha = alpha)\n","\n","ax.set_ylabel('Number of Students')\n","ax.set_title('CRDC Counts of LEP Students by State (2015)')\n","ax.legend()\n","\n","plt.xticks(rotation = 90)\n","plt.show()"],"metadata":{"id":"fvYdaofcLo4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Preproccessing 2014 & 2012  CRDC Data\n","\n","enrollment2013 = pd.read_excel('2013-14 CRDC/School/CRDC-collected data file for Schools/03 Enrollment.xlsx')\n","\n","state_codes = enrollment2013['LEA_STATE'].unique()\n","state_totals2013 = pd.DataFrame()\n","for state in state_codes:\n","  val = enrollment2013.loc[enrollment2013['LEA_STATE'] == state]\n","  val = val.append(val.sum(numeric_only=True), ignore_index = True)\n","  row = val.iloc[-1:]\n","  #row.rename(columns={\"LEA_STATE\": \"State\"}, inplace = True)\n","  row.rename(index={(row.index[0]): int(np.where(state_codes==state)[0][0])}, inplace = True)\n","  row.dropna(axis=1, inplace = True)\n","  state_totals2013 = state_totals2013.append(row)\n","\n","enrollment2011 = pd.read_excel('2011-12 Public Use File/School/CRDC -collected data file for Schools/Pt 1-Enrollment/SCH_CRDC-collected data file for Schools_Pt 1-Enrollment_09-1 - Students who are Limited English Proficient.xlsx')\n","\n","col_names = enrollment2011.columns\n","for i in range(7, 24):\n","    enrollment2011[col_names[i]] = enrollment2011[col_names[i]].replace(r'^\\s*$', np.nan, regex=True)\n","    enrollment2011[col_names[i]] = enrollment2011[col_names[i]].replace(r'â€¡', np.nan, regex=True)\n","    enrollment2011[col_names[i]] = enrollment2011[col_names[i]].astype(float)\n","    #enrollment2011[col_names[i]] = pd.to_numeric(enrollment2011[col_names[i]], errors='ignore')\n","\n","state_codes = enrollment2011['LEA_STATE'].unique()\n","state_totals2011 = pd.DataFrame()\n","for state in state_codes:\n","  val = enrollment2011.loc[enrollment2011['LEA_STATE'] == state]\n","  val = val.append(val.sum(numeric_only=True), ignore_index = True)\n","  row = val.iloc[-1:]\n","  row.rename(columns={\"LEA_STATE\": \"State\"}, inplace = True)\n","  row.rename(index={(row.index[0]): int(np.where(state_codes==state)[0][0])}, inplace = True)\n","  row.dropna(axis=1, inplace = True)\n","  state_totals2011 = state_totals2011.append(row)\n","\n","state_totals2013['State'] = enrollment2013['LEA_STATE'].unique()\n","state_totals2011['State'] = enrollment2011['LEA_STATE'].unique()\n","\n","st13 = pd.DataFrame()\n","st11 = pd.DataFrame()\n","for state in state_totals2017['State']:\n","  st13 = st13.append(state_totals2013.loc[state_totals2013['State'] == state])\n","  st11 = st11.append(state_totals2011.loc[state_totals2011['State'] == state])\n","st13 = st13.reset_index()\n","st11 = st11.reset_index()\n","st13.drop(columns = ['index'], inplace = True)\n","st11.drop(columns = ['index'], inplace = True)"],"metadata":{"id":"lq_aoGxvNIWe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lep2015 = pd.read_csv(\"acs2013_lep_allstate.csv\", encoding='windows-1252')\n","lep2014 = pd.read_csv(\"acs2014_lep_allstate.csv\", encoding='windows-1252')\n","lep2012 = pd.read_csv(\"acs2012_lep_allstate.csv\", encoding='windows-1252')\n","\n","def rename(lep):\n","  lep['LEP White'] = lep['French (incl. Patois, Cajun)'] + lep['French Creole'] + lep['Italian'] + lep['Portuguese/Portuguese Creole'] + lep['German'] + lep['Yiddish'] + lep['Other West Germanic langs.'] + lep['Greek'] + lep['Russian'] + lep['Polish'] + lep['Serbo-Croatian'] + lep['Other Slavic langs.'] + lep['Armenian'] + lep['Hungarian'] + lep['Other Indo-European langs.']\n","  lep['LEP Hispanic'] = lep['Spanish or Spanish Creole']\n","  lep['LEP Native American'] = lep['Navajo'] + lep['Other Native North American']\n","  lep['LEP Asian'] = lep['Gujarati'] + lep['Hindi'] + lep['Urdu'] + lep['Other Indic langs.'] + lep['Chinese'] + lep['Japanese'] + lep['Korean'] + lep['Mon-Khmer(Cambodian)'] + lep['Hmong'] + lep['Thai'] + lep['Laotian'] + lep['Vietnamese'] + lep['Other Asian langs.'] + lep['Arabic']# + lep['Hebrew']\n","  lep['LEP Native Hawaiian'] = lep['Tagalog'] + lep['Other Pacific Island langs.']\n","  lep['LEP Black'] = lep['African langs.'] \n","\n","rename(lep2015)\n","rename(lep2014)\n","rename(lep2012)\n","\n","lep2012.drop(labels=[49], axis = 0, inplace = True)\n","lep2012 = lep2012.sort_values('Location')\n","col_renamer = {}\n","ogindex = lep2012.index\n","for i in range(0, 51):\n","  col_renamer[ogindex[i]] = i\n","lep2012.rename(col_renamer, axis=0, inplace = True)\n","\n","lep2014.drop(labels=[51], axis = 0, inplace = True)\n","lep2015.drop(labels=[51], axis = 0, inplace = True)"],"metadata":{"id":"EQ-e1iuuPOTs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def standardize15(df):\n","  df['LEP Hispanic Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): Hispanic Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): Hispanic Female\"])\n","  df['LEP Native American Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): American Indian/Alaska Native Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): American Indian/Alaska Native Female\"])\n","  df['LEP Asian Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): Asian Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): Asian Female\"])\n","  df['LEP Native Hawaiian Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): Native Hawaiian/Pacific Islander Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): Native Hawaiian/Pacific Islander Female\"])\n","  df['LEP Black Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): Black Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): Black Female\"])\n","  df['LEP White Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): White Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): White Female\"])\n","  df['Percent LEP Hispanic Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): Hispanic Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): Hispanic Female\"])/(df['Overall Student Enrollment: Calculated Male Total'] + df['Overall Student Enrollment: Calculated Female Total'])\n","  df['Percent LEP Native American Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): American Indian/Alaska Native Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): American Indian/Alaska Native Female\"])/(df['Overall Student Enrollment: Calculated Male Total'] + df['Overall Student Enrollment: Calculated Female Total'])\n","  df['Percent LEP Asian Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): Asian Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): Asian Female\"])/(df['Overall Student Enrollment: Calculated Male Total'] + df['Overall Student Enrollment: Calculated Female Total'])\n","  df['Percent LEP Native Hawaiian Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): Native Hawaiian/Pacific Islander Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): Native Hawaiian/Pacific Islander Female\"])/(df['Overall Student Enrollment: Calculated Male Total'] + df['Overall Student Enrollment: Calculated Female Total'])\n","  df['Percent LEP Black Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): Black Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): Black Female\"])/(df['Overall Student Enrollment: Calculated Male Total'] + df['Overall Student Enrollment: Calculated Female Total'])\n","  df['Percent LEP White Students'] = (df[\"Enrollment of Students who are Limited English Proficient (LEP): White Male\"] + df[\"Enrollment of Students who are Limited English Proficient (LEP): White Female\"])/(df['Overall Student Enrollment: Calculated Male Total'] + df['Overall Student Enrollment: Calculated Female Total'])\n","\n","standardize(state_totals2015)\n","\n","def standardize14(df):\n","  df['LEP Hispanic Students'] = df['SCH_LEPENR_HI_M'] + df['SCH_LEPENR_HI_F']\n","  df['LEP Native American Students'] = df['SCH_LEPENR_AM_M'] + df['SCH_LEPENR_AM_F']\n","  df['LEP Asian Students'] = df['SCH_LEPENR_AS_M'] + df['SCH_LEPENR_AS_F']\n","  df['LEP Native Hawaiian Students'] = df['SCH_LEPENR_HP_M'] + df['SCH_LEPENR_HP_F']\n","  df['LEP Black Students'] = df['SCH_LEPENR_BL_M'] + df['SCH_LEPENR_BL_F']\n","  df['LEP White Students'] = df['SCH_LEPENR_BL_M'] + df['SCH_LEPENR_BL_F']\n","  df['Percent LEP White Students'] = df['LEP White Students']/(df['TOT_LEPPROGENR_M'] + df['TOT_LEPPROGENR_F']) * 100\n","  df['Percent LEP Hispanic Students'] = df['LEP Hispanic Students']/(df['TOT_LEPPROGENR_M'] + df['TOT_LEPPROGENR_F']) * 100\n","  df['Percent LEP Native American Students'] = df['LEP Native American Students']/(df['TOT_LEPPROGENR_M'] + df['TOT_LEPPROGENR_F']) * 100\n","  df['Percent LEP Asian Students'] = df['LEP Asian Students']/(df['TOT_LEPPROGENR_M'] + df['TOT_LEPPROGENR_F']) * 100\n","  df['Percent LEP Native Hawaiian Students'] = df['LEP Native Hawaiian Students']/(df['TOT_LEPPROGENR_M'] + df['TOT_LEPPROGENR_F']) * 100\n","  df['Percent LEP Black Students'] = df['LEP Black Students']/(df['TOT_LEPPROGENR_M'] + df['TOT_LEPPROGENR_F']) * 100\n","\n","standardize14(st13)\n","\n","def standardize12(df):\n","  df['LEP Hispanic Students'] = df['M_HIS_7_LEP'] + df['F_HIS_7_LEP']\n","  df['LEP Native American Students'] = df['M_AME_7_LEP'] + df['F_AME_7_LEP']\n","  df['LEP Asian Students'] = df['M_ASI_7_LEP'] + df['F_ASI_7_LEP']\n","  df['LEP Native Hawaiian Students'] = df['M_HI_PAC_7_LEP'] + df['F_HI_PAC_7_LEP']\n","  df['LEP Black Students'] = df['M_BLA_7_LEP'] + df['F_BLA_7_LEP']\n","  df['LEP White Students'] = df['M_WHI_7_LEP'] + df['F_WHI_7_LEP']\n","  df['Percent LEP White Students'] = df['LEP White Students']/(df['M_TOT_7_LEP'] + df['F_TOT_7_LEP']) * 100\n","  df['Percent LEP Hispanic Students'] = df['LEP Hispanic Students']/(df['M_TOT_7_LEP'] + df['F_TOT_7_LEP']) * 100\n","  df['Percent LEP Native American Students'] = df['LEP Native American Students']/(df['M_TOT_7_LEP'] + df['F_TOT_7_LEP']) * 100\n","  df['Percent LEP Asian Students'] = df['LEP Asian Students']/(df['M_TOT_7_LEP'] + df['F_TOT_7_LEP']) * 100\n","  df['Percent LEP Native Hawaiian Students'] = df['LEP Native Hawaiian Students']/(df['M_TOT_7_LEP'] + df['F_TOT_7_LEP']) * 100\n","  df['Percent LEP Black Students'] = df['LEP Black Students']/(df['M_TOT_7_LEP'] + df['F_TOT_7_LEP']) * 100\n","  \n","standardize12(st11)"],"metadata":{"id":"J_3Sr2WoPObD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["columns = ['Years Since 2010', 'State', 'LEP Hispanic', 'LEP White', 'LEP Native American', 'LEP Asian', 'LEP Native Hawaiian', 'LEP Black', 'LEP Black Students', 'LEP Hispanic Students', 'LEP White Students', 'LEP Native American Students', 'LEP Asian Students', 'LEP Native Hawaiian Students']"],"metadata":{"id":"H5FQ4IqBQ9AZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y12 = pd.DataFrame()\n","y14 = pd.DataFrame()\n","y15 = pd.DataFrame()\n","\n","def add_cols(df, columns):\n","  for col in columns:\n","    df[col] = np.NaN\n","\n","add_cols(y12, columns)\n","add_cols(y14, columns)\n","add_cols(y15, columns)\n","\n","y12['State'] = state_totals2015['State']\n","y14['State'] = state_totals2015['State']\n","y15['State'] = state_totals2015['State']\n","\"\"\"\n","y12['Years Since 2010'] = 2\n","y14['Years Since 2010'] = 4\n","y15['Years Since 2010'] = 5\n","\"\"\"\n","CRDC_Metrics = ['LEP Hispanic Students', 'LEP White Students', 'LEP Native American Students', 'LEP Asian Students', 'LEP Black Students', 'LEP Native Hawaiian Students', 'Percent LEP Hispanic Students', 'Percent LEP White Students', 'Percent LEP Native American Students', 'Percent LEP Asian Students', 'Percent LEP Native Hawaiian Students']\n","Survey_Metrics = ['LEP Hispanic', 'LEP White', 'LEP Native American', 'LEP Asian', 'LEP Black', 'LEP Native Hawaiian', 'Percent LEP Hispanic', 'Percent LEP White', 'Percent LEP Native American', 'Percent LEP Asian', 'Percent LEP Native Hawaiian']\n","\n","for col in Survey_Metrics:\n","  y12[col] = lep2012[col]\n","  y14[col] = lep2014[col]\n","  y15[col] = lep2015[col]\n","\n","for col in CRDC_Metrics:\n","  y12[col] = st11[col]\n","  y14[col] = st13[col]\n","  y15[col] = state_totals2015[col]\n","\n","\"\"\"\n","y12 = y12.append(y14, ignore_index = True)\n","y12 = y12.append(y15, ignore_index = True)\n","data = y12\n","\"\"\"\n","\n","df = y12.merge(y14, on = 'State')\n","df.drop(columns = ['Years Since 2010_x', 'Years Since 2010_y'], inplace = True)\n","\n","df_output = y15\n","df_output.drop(columns = ['Years Since 2010'], inplace = True)\n","\n","df = df.reset_index()\n","df_output = df_output.reset_index()\n","df_output.drop(columns = ['index'], inplace = True)\n","df.drop(columns = ['index'], inplace = True)\n","df.drop(columns = ['State'], inplace = True)\n","df_output.drop(columns = ['State'], inplace = True)"],"metadata":{"id":"IQ1xHHH0RWsW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def r_square(pred, output, index):\n","  ss_res = np.sum((pred - output.iloc[index])**2)\n","  ss_total = np.sum((pred - output.mean())**2)\n","  return 1 - ss_res/ss_total\n","\n","def r_square_per_feature(pred, output, index):\n","  out = output.iloc[index].to_numpy()\n","  ss_res = (pred - out)**2\n","  ss_total = (pred - output.mean(axis = 0))**2\n","  return(1-(ss_res/ss_total), (pred - out))  \n","\n","CRDC_Metrics = ['LEP Hispanic Students', 'LEP White Students', 'LEP Native American Students', 'LEP Asian Students', 'LEP Native Hawaiian Students', 'LEP Black Students']\n","Survey_Metrics = ['LEP Hispanic', 'LEP White', 'LEP Native American', 'LEP Asian', 'LEP Native Hawaiian', 'LEP Black']\n","\n","CRDC_input = ['LEP Hispanic Students_x', 'LEP White Students_x', 'LEP Native American Students_x', 'LEP Asian Students_x', 'LEP Native Hawaiian Students_x', 'LEP Black Students_x', 'LEP Hispanic Students_y', 'LEP White Students_y', 'LEP Native American Students_y', 'LEP Asian Students_y', 'LEP Native Hawaiian Students_y', 'LEP Black Students_y']\n","Survey_input = ['LEP Hispanic_x', 'LEP White_x', 'LEP Native American_x', 'LEP Asian_x', 'LEP Native Hawaiian_x', 'LEP Black_x', 'LEP Hispanic_y', 'LEP White_y', 'LEP Native American_y', 'LEP Asian_y', 'LEP Native Hawaiian_y', 'LEP Black_y']\n","\n","def add_polynomial_features(df, degree):\n","    poly = PolynomialFeatures(degree=degree, include_bias=False)\n","    poly_features = poly.fit_transform(df)\n","    poly_features = pd.DataFrame(poly_features, columns=poly.get_feature_names([df.columns[0]]))\n","    return poly_features\n","\n","def renamer(squo, new):\n","  renamer_index = {}\n","  for i in range(len(squo)):\n","    renamer_index[squo[i]] = new[i]\n","  return(renamer_index)\n","\n","CRDC_df = df[CRDC_input]\n","CRDC_output = df_output[CRDC_Metrics]\n","\n","Census_df = df[Survey_input]\n","Census_output = df_output[Survey_Metrics]\n","\n","CRDC_df.rename(columns = renamer(CRDC_input, Survey_input), inplace = True)\n","CRDC_output.rename(columns = renamer(CRDC_Metrics, Survey_Metrics), inplace = True)\n","\n","\n","print(\"\\n---------------------Building CRDC Model---------------------\")\n","performance = 0 \n","for index in CRDC_df.index:\n","  #print(state_totals2017.loc[index, 'State'])\n","  k_in = CRDC_df.loc[CRDC_df.index != index]\n","  k_out = CRDC_output.loc[CRDC_output.index != index]\n","  model.fit(k_in, k_out)\n","  k_pred = model.predict([CRDC_df.iloc[index]])\n","  r_squared = r_square(k_pred[0], CRDC_output, index)\n","  performance += r_squared\n","  r_squa, direction = r_square_per_feature(k_pred[0], CRDC_output, index)\n","  print(state_totals2017.loc[index, 'State'])\n","  print(index)\n","  print(\"Overall: \" + str(r_squared))\n","  print(\"Features: \")\n","  print(r_squa)\n","  print(\"\\n* * * * * * * * * * * * * * * * *\\n\")\n","print(\"\\n\\nCulmulative Performance: \" + str(performance/51))\n","\n","print(\"\\n---------------------Building Census Model---------------------\")\n","performance = 0 \n","for index in Census_df.index:\n","  #print(state_totals2017.loc[index, 'State'])\n","  k_in = Census_df.loc[Census_df.index != index]\n","  k_out = Census_output.loc[Census_output.index != index]\n","  model.fit(k_in, k_out)\n","  k_pred = model.predict([Census_df.iloc[index]])\n","  r_squared = r_square(k_pred[0], Census_output, index)\n","  performance += r_squared\n","  r_squa, direction = r_square_per_feature(k_pred[0], Census_output, index)\n","  print(state_totals2017.loc[index, 'State'])\n","  print(index)\n","  print(\"Overall: \" + str(r_squared))\n","  print(\"Features: \")\n","  print(r_squa)\n","  print(\"\\n* * * * * * * * * * * * * * * * *\\n\")\n","print(\"\\n\\n\\nCulmulative Performance: \" + str(performance/51))"],"metadata":{"id":"dKC2pYvATPl7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["crdc_modified = CRDC_df.loc[CRDC_df.index != 2]\n","crdc_output_m = CRDC_output.loc[CRDC_output.index != 2]\n","performance = 0 \n","#for index in crdc_modified.index:\n","for index in range(0, 50):\n","  #print(state_totals2017.loc[index, 'State'])\n","  k_in = crdc_modified.loc[crdc_modified.index != index]\n","  k_out = crdc_output_m.loc[crdc_output_m.index != index]\n","  model.fit(k_in, k_out)\n","  k_pred = model.predict([crdc_modified.iloc[index]])\n","  r_squared = r_square(k_pred[0], crdc_output_m, index)\n","  performance += r_squared\n","  r_squa, direction = r_square_per_feature(k_pred[0], crdc_output_m, index)\n","  print(state_totals2017.loc[index, 'State'])\n","  print(index)\n","  print(\"Overall: \" + str(r_squared))\n","  print(\"Features: \")\n","  print(r_squa)\n","  print(\"\\n* * * * * * * * * * * * * * * * *\\n\")\n","print(\"\\n\\nCulmulative Performance: \" + str(performance/50)+ \"\\n\\n\\n\")"],"metadata":{"id":"JsbZU8T4Wx1f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CRDC_Mod = model.fit(crdc_modified, crdc_output_m)\n","estimation = CRDC_Mod.predict(Census_df)\n","predictions = (Census_output - estimation)\n","predictions.sum(axis = 0)"],"metadata":{"id":"GZrqc5vtW2CU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Census_output.sum(axis = 0)"],"metadata":{"id":"06YYlxEcXQlm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CRDC_Mod = model.fit(crdc_modified, crdc_output_m)\n","estimation = CRDC_Mod.predict(Census_df)\n","estimation.sum(axis = 0)"],"metadata":{"id":"elfKMhaYXc_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["figure(figsize=(10, 10), dpi=80)\n","\n","metrics = ['LEP Hispanic', 'LEP White', 'LEP Native American', 'LEP Asian', 'LEP Native Hawaiian', 'LEP Black']\n","width = 1      \n","alpha = 0.70\n","fig, ax = plt.subplots()\n","ax.bar(metrics, estimation.sum(axis = 0), width, label = 'Predicted Value', alpha = alpha)\n","ax.bar(metrics, Census_output.sum(axis= 0), width, label = 'Census Data', alpha = alpha)\n","ax.set_ylabel('Number of People')\n","ax.set_title('National LEP Populations: CRDC Model Predictions vs. Census Bureau Surveyed')\n","ax.legend()\n","plt.xticks(rotation = 60)\n","plt.show()"],"metadata":{"id":"FcCvBVXcXeyd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","\"\"\"\n","def print_state_data(sus_states, net_impact):\n","  keys = sus_states.keys()\n","  print(\"\\n* * * * * * States that Lost Reps * * * * * *\")\n","  for state in lost_reps_states:\n","    if state in keys:\n","      print(\"\\n\" + state)\n","      print(sus_states[state])\n","      print(\"Net Impact: \" + str(net_impact[state]))\n","  print(\"\\n* * * * * * States that Gained Reps * * * * * *\")\n","  for state in gained_reps_states:\n","    if state in keys:\n","      print(\"\\n\" + state)\n","      print(sus_states[state])\n","      print(\"Net Impact: \" + str(net_impact[state]))\n","  print(\"\\n* * * * * * Neither * * * * * *\")\n","  for state in keys:\n","    if state not in lost_reps_states and state not in gained_reps_states:\n","      print(\"\\n\" + state)\n","      print(sus_states[state])\n","      print(\"Net Impact: \" + str(net_impact[state]))\n","\"\"\"\n","def print_state_data(sus_states, sus_states_two, net_impact):\n","  keys = sus_states.keys()\n","  for state in keys:\n","    print(\"\\n\" + state)\n","    metrics = sus_states[state].keys()\n","    for metric in metrics:\n","      if metric in sus_states_two[state].keys():\n","        if ('Overcounted' in sus_states[state][metric] and 'Overcounted' in sus_states_two[state][metric]) or ('Undercounted' in sus_states[state][metric] and 'Undercounted' in sus_states_two[state][metric]):\n","          print(str(metric) + \" : \" + str(sus_states[state][metric]))\n","    #print(\"Net Impact: \" + str(net_impact[state]))\n","\n","#print(\"\\n---------------------Predicting Census Data Using CRDC Model---------------------\")\n","CRDC_Model = model.fit(CRDC_df, CRDC_output)\n","estimation = CRDC_Model.predict(Census_df)\n","#print(estimation)\n","predictions = (Census_output - estimation)/(estimation)\n","net = (Census_output - estimation).sum(axis = 1)\n","error_threshold = .1\n","state_errors = {}\n","impacts = {}\n","for index in range(len(predictions)):\n","  discrpencies = {}\n","  for col in predictions.columns:\n","    val = predictions.loc[index, col]\n","    if math.sqrt(float(val)**2) > error_threshold:\n","      if val < 0:\n","        discrpencies[col] = ('Undercounted by ' + str(val * 100) + '%')\n","      else:\n","        discrpencies[col] = ('Overcounted by ' + str(val * 100) + '%')\n","  #if len(discrpencies) !=  0:\n","  state_errors[state_totals2017.loc[index, 'State']] = discrpencies\n","  impacts[state_totals2017.loc[index, 'State']] = net[index]\n","#print_state_data(state_errors, impacts)\n","\n","print(\"\\n---------------------Predicting CRDC Data Using Census Model---------------------\")\n","Census_Model = model.fit(Census_df, Census_output)\n","estimation = Census_Model.predict(CRDC_df)\n","predictions = (estimation - CRDC_output)/(CRDC_output)\n","net = (CRDC_output - estimation).sum(axis = 1)\n","error_threshold = .1\n","census_state_errors = {}\n","#impacts = {}\n","impacts  = {'LEP Hispanic':[], 'LEP White':[], 'LEP Black':[], 'LEP Native American':[], 'LEP Native Hawaiian':[], 'LEP Asian':[]}\n","for index in range(len(predictions)):\n","  discrpencies = {}\n","  for col in predictions.columns:\n","    val = predictions.loc[index, col]\n","    if math.sqrt(float(val)**2) > error_threshold:\n","      if val < 0:\n","        discrpencies[col] = ('Undercounted by ' + str(val * 100) + '%')\n","      else:\n","        discrpencies[col] = ('Overcounted by ' + str(val * 100) + '%')\n","  #if len(discrpencies) !=  0:\n","  census_state_errors[state_totals2017.loc[index, 'State']] = discrpencies\n","  impacts[state_totals2017.loc[index, 'State']] = net[index]\n","print_state_data(state_errors, census_state_errors, impacts)"],"metadata":{"id":"43rJQxszXffD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","keys = {'LEP Hispanic':0, 'LEP White':1, 'LEP Native American':2, 'LEP Asian':3, 'LEP Native Hawaiian':4, 'LEP Black':5}\n","CRDC_Model = model.fit(CRDC_df, CRDC_output)\n","cr_estimations = CRDC_Model.predict(Census_df)\n","cr_errors = (Census_output - cr_estimations)\n","cr_predictions = (Census_output - cr_estimations)/(cr_estimations)\n","Census_Model = model.fit(Census_df, Census_output)\n","census_estimations = Census_Model.predict(CRDC_df)\n","census_predictions = CRDC_output - census_estimations \n","error_threshold = .1\n","net_impact = {'LEP Hispanic':0, 'LEP White':0, 'LEP Native American':0, 'LEP Asian':0, 'LEP Native Hawaiian':0, 'LEP Black':0}\n","net_impact2 = {'LEP Hispanic':0, 'LEP White':0, 'LEP Native American':0, 'LEP Asian':0, 'LEP Native Hawaiian':0, 'LEP Black':0}\n","net_impact3 = {'LEP Hispanic':0, 'LEP White':0, 'LEP Native American':0, 'LEP Asian':0, 'LEP Native Hawaiian':0, 'LEP Black':0}\n","impacts  = {'LEP Hispanic':[], 'LEP White':[], 'LEP Black':[], 'LEP Native American':[], 'LEP Native Hawaiian':[], 'LEP Asian':[]}\n","for index in range(len(cr_predictions)):\n","  for col in cr_predictions.columns:\n","    cr_val = cr_predictions.loc[index, col]\n","    census_val = census_predictions.loc[index, col]\n","    if (cr_estimations[index][keys[col]] > 0): #and (math.sqrt(float(cr_val)**2) > error_threshold):\n","      net_impact3[col] += cr_errors.loc[index, col]\n","      if (math.sqrt(float(cr_val)**2) > error_threshold):\n","        net_impact2[col] += cr_errors.loc[index, col]\n","        if ((cr_val < 0 and census_val < 0) or (cr_val > 0 and census_val > 0)) and cr_val < 5:\n","          #print(\"\\n**************************\\n\")\n","          #print(cr_val)\n","          #print(census_val)\n","          #print(cr_errors.loc[index, col])\n","          #impacts[col].append(cr_val*100)\n","          impacts[col].append(cr_errors.loc[index, col])\n","          net_impact[col] += cr_errors.loc[index, col]\n","        else:\n","          impacts[col].append(0)\n","      else:\n","        impacts[col].append(0)\n","    else:\n","      impacts[col].append(0)\n","print(\"\\n------------------- Raw Predictions -------------------\\n\")\n","print(net_impact3)\n","print(\"\\n------------------- With Error Threshold -------------------\\n\")\n","print(net_impact2)\n","print(\"\\n------------------- Error Threshold & Cross Checked -------------------\\n\")\n","print(net_impact)"],"metadata":{"id":"LtPwKeFNX_qv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = state_totals2015['State']\n","plt.rcParams[\"figure.figsize\"] = [12.00, 5]\n","#width = 1\n","alpha = 0.5\n","fig, ax = plt.subplots()\n","\n","#ax.bar(labels, LEP_Hisp, width, label='LEP Hispanic')\n","ax.bar(labels, impacts['LEP Native American'], width, label='LEP Native American', alpha = alpha)\n","ax.bar(labels, impacts['LEP Asian'], width, label='LEP Asian', alpha = alpha)\n","ax.bar(labels, impacts['LEP Native Hawaiian'], width, label='LEP Native Hawaiian', alpha = alpha)\n","ax.bar(labels, impacts['LEP Black'], width, label='LEP Black', alpha = alpha)\n","ax.bar(labels, impacts['LEP White'], width, label='LEP White' , alpha = alpha)\n","ax.bar(labels, impacts['LEP Hispanic'], width, label='LEP Hispanic' , alpha = alpha)\n","#ax.bar(labels, state_totals2015['LEP Hispanic Students'].to_numpy(), width, label='LEP Hispanic Students' , alpha = alpha)\n","\n","ax.set_ylabel('Nominal Difference')\n","ax.set_title('Nominal Over/Undercounts of LEP Ethnic Groups by State')\n","ax.legend()\n","\n","plt.xticks(rotation = 90)\n","plt.show()"],"metadata":{"id":"s9I_-NB8YDZ9"},"execution_count":null,"outputs":[]}]}